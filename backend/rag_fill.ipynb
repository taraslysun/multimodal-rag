{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e25fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taras/Documents/work/test_tasks/softserve/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import io\n",
    "from rag_system.embedding import load_sentence_embedding_model, load_clip_model\n",
    "from rag_system.faiss_utils import load_faiss_index\n",
    "from rag_system.mongo_utils import init_mongo_collections\n",
    "from rag_system.prompt_builder import init_gemini_client\n",
    "from rag_system.multimodal_rag import MultimodalRAG\n",
    "from rag_system.ingest import batch_ingest_all\n",
    "from rag_system.utils import normalize_embedding\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from config import (\n",
    "    FAISS_INDEX_PATH,\n",
    "    DB_NAME,\n",
    "    GEMINI_API_KEY,\n",
    "    GEMINI_MODEL_NAME,\n",
    "    TOP_K,\n",
    "    FAISS_DIM,\n",
    "    TEXT_COLLECTION_NAME,\n",
    "    MONGO_URI,\n",
    "    IMAGE_COLLECTION_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71174f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize all models, clients, and collections using the modular rag_system code\n",
    "load_dotenv()\n",
    "\n",
    "gemini_client = init_gemini_client(GEMINI_API_KEY)\n",
    "faiss_index = load_faiss_index(FAISS_INDEX_PATH)\n",
    "mongo_client, text_col, image_col = init_mongo_collections()\n",
    "text_model = load_sentence_embedding_model()\n",
    "clip_model, clip_processor = load_clip_model()\n",
    "\n",
    "rag = MultimodalRAG(\n",
    "    gemini_client=gemini_client,\n",
    "    faiss_index=faiss_index,\n",
    "    text_collection=text_col,\n",
    "    image_collection=image_col,\n",
    "    text_model=text_model,\n",
    "    clip_model=clip_model,\n",
    "    clip_processor=clip_processor,\n",
    "    gemini_model_name=GEMINI_MODEL_NAME,\n",
    "    top_k=TOP_K,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2443f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x775252c387b0> >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "def init_faiss_index(dim: int = FAISS_DIM):\n",
    "    \"\"\"\n",
    "    If an index already exists on disk at FAISS_INDEX_PATH, delete it and create a new empty IndexFlatIP.\n",
    "    Otherwise, create a new one. Returns the new FAISS index object.\n",
    "    \"\"\"\n",
    "    # Optionally, you can remove the old file to start fresh:\n",
    "    # Create a new raw IndexFlatIP\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    # Optionally, you can save the new index to disk\n",
    "    faiss.write_index(index, FAISS_INDEX_PATH)\n",
    "    return index\n",
    "init_faiss_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b57f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mongo_cursor(collection, batch_size: int):\n",
    "    \"\"\"\n",
    "    Return a PyMongo cursor over the entire collection,\n",
    "    with a specified batch_size for server‐side pagination.\n",
    "    \"\"\"\n",
    "    return collection.find({}, batch_size=batch_size)\n",
    "\n",
    "cursor = get_mongo_cursor(text_col, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba778cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_text_chunks(rag, docs: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a list of text_docs (each has \"text_chunk\"), embed all with SentenceTransformer in one batch.\n",
    "    Returns a (N, dim) numpy array of normalized float32 embeddings.\n",
    "    \"\"\"\n",
    "    chunks = [d[\"text_chunk\"] for d in docs]\n",
    "    with torch.no_grad():\n",
    "        embs = rag.text_model.encode(chunks, convert_to_numpy=True)\n",
    "    # Normalize each vector\n",
    "    embs = np.vstack([normalize_embedding(e) for e in embs]).astype(np.float32)\n",
    "    return embs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33887cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_image_docs(rag, docs: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a list of image_docs, each with:\n",
    "      - type == \"image\": use rag.embed_image on the downloaded image\n",
    "      - type in (\"ocr\", \"gemini_desc\", \"alt_text\"): embed the corresponding text field\n",
    "    Returns a (N, dim) numpy array of normalized float32 embeddings.\n",
    "    \"\"\"\n",
    "    embs = []\n",
    "    for doc in docs:\n",
    "        mtype = doc.get(\"type\")\n",
    "        if mtype == \"image\":\n",
    "            url = doc.get(\"image_url\", \"\")\n",
    "            img_bytes = rag.download_image_bytes(url)\n",
    "            if not img_bytes:\n",
    "                # fallback zero‐vector (will be near zero)\n",
    "                dim = FAISS_DIM\n",
    "                embs.append(np.zeros(dim, dtype=np.float32))\n",
    "                continue\n",
    "            try:\n",
    "                pil = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "                emb = rag.embed_image(pil)\n",
    "                embs.append(emb.astype(np.float32))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed embedding for {mtype}: {e}\")\n",
    "                dim = FAISS_DIM\n",
    "                embs.append(np.zeros(dim, dtype=np.float32))\n",
    "        else:\n",
    "            # “ocr”, “gemini_desc”, or “alt_text”\n",
    "            text = \"\"\n",
    "            if mtype == \"ocr\":\n",
    "                text = doc.get(\"ocr_text\", \"\")\n",
    "            elif mtype == \"gemini_desc\":\n",
    "                text = doc.get(\"desc_text\", \"\")\n",
    "            elif mtype == \"alt_text\":\n",
    "                text = doc.get(\"alt_text\", \"\")\n",
    "            try:\n",
    "                emb = rag.embed_text(text)\n",
    "                embs.append(emb.astype(np.float32))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed embedding for {mtype}: {e}\")\n",
    "                dim = FAISS_DIM\n",
    "                embs.append(np.zeros(dim, dtype=np.float32))\n",
    "\n",
    "    return np.vstack(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba057cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flush_to_faiss_and_mongo(rag, \n",
    "                              text_embs: np.ndarray, text_docs: list,\n",
    "                              img_embs: np.ndarray, img_docs: list):\n",
    "    \"\"\"\n",
    "    1) Bulk-add text_embs (shape: [N_text, dim]) to FAISS, assign vector_id to text_docs.\n",
    "    2) Bulk-add img_embs  (shape: [N_img,  dim]) to FAISS, assign vector_id to img_docs.\n",
    "    3) Bulk-update MongoDB docs: set new vector_id for each.\n",
    "    \"\"\"\n",
    "    # 1) Flush text embeddings\n",
    "    if len(text_embs) > 0:\n",
    "        start = rag.faiss_index.ntotal\n",
    "        rag.faiss_index.add(text_embs)\n",
    "        # Now assign vector_id back to text_docs\n",
    "        for i, doc in enumerate(text_docs):\n",
    "            vid = start + i\n",
    "            doc[\"vector_id\"] = int(vid)\n",
    "\n",
    "        # Bulk‐write updated vector_id fields into MongoDB\n",
    "        for doc in text_docs:\n",
    "            _id = doc[\"_id\"]\n",
    "            new_vid = doc[\"vector_id\"]\n",
    "            # write each doc back to MongoDB\n",
    "            rag.text_collection.update_one(\n",
    "                {\"_id\": _id},\n",
    "                {\"$set\": {\"vector_id\": new_vid}}\n",
    "            )\n",
    "\n",
    "\n",
    "    # 2) Flush image embeddings\n",
    "    if len(img_embs) > 0:\n",
    "        start = rag.faiss_index.ntotal\n",
    "        rag.faiss_index.add(img_embs)\n",
    "        for i, doc in enumerate(img_docs):\n",
    "            vid = start + i\n",
    "            doc[\"vector_id\"] = int(vid)\n",
    "\n",
    "        for doc in img_docs:\n",
    "            _id = doc[\"_id\"]\n",
    "            new_vid = doc[\"vector_id\"]\n",
    "            # write each doc back to MongoDB\n",
    "            rag.image_collection.update_one(\n",
    "                {\"_id\": _id},\n",
    "                {\"$set\": {\"vector_id\": new_vid}}\n",
    "            )\n",
    "    print(f\"Flushed {len(text_embs)} text and {len(img_embs)} image embeddings to FAISS and MongoDB.\")\n",
    "    # 3) Flush text and image docs to MongoDB\n",
    "    # (this is already done in the above loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7251382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "def reindex_all(rag, batch_size: int = 100, mini_batch_size: int = 500):\n",
    "    \"\"\"\n",
    "    1) Initializes a new empty FAISS index.\n",
    "    2) Reads text_chunks and image_embeddings collections in batches (batch_size).\n",
    "    3) Accumulates embeddings + docs in lists.\n",
    "    4) Every time (len(text_embs) + len(img_embs)) >= mini_batch_size, calls _flush_to_faiss_and_mongo.\n",
    "    5) After all documents, does one final flush and saves FAISS index.\n",
    "    \"\"\"\n",
    "    # 1) Initialize new FAISS index\n",
    "    rag.faiss_index = init_faiss_index(dim=FAISS_DIM)\n",
    "\n",
    "    # 2) Connect to Mongo collections\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    text_col = db[TEXT_COLLECTION_NAME]\n",
    "    img_col  = db[IMAGE_COLLECTION_NAME]\n",
    "\n",
    "    # Initialize accumulators\n",
    "    all_text_docs = []\n",
    "    all_text_embs = []\n",
    "    all_img_docs  = []\n",
    "    all_img_embs  = []\n",
    "\n",
    "    # 3) Iterate text_docs in pages\n",
    "    text_cursor = get_mongo_cursor(text_col, batch_size=batch_size)\n",
    "    for text_doc in text_cursor:\n",
    "        all_text_docs.append(text_doc)\n",
    "        # We'll embed in mini‐batches below\n",
    "\n",
    "        # When we reach mini_batch size, embed & flush\n",
    "        if len(all_text_docs) >= mini_batch_size:\n",
    "            # Embed this mini‐batch of text  \n",
    "            text_emb_batch = embed_text_chunks(rag, all_text_docs)\n",
    "            # Clear the accumulator after copying to local\n",
    "            tdocs = all_text_docs.copy()\n",
    "            all_text_docs.clear()\n",
    "\n",
    "            # No images yet, so img_embs and img_docs empty for this flush\n",
    "            _flush_to_faiss_and_mongo(rag, text_emb_batch, tdocs, np.zeros((0, FAISS_DIM), dtype=np.float32), [])\n",
    "\n",
    "    # After text cursor, if any remain\n",
    "    if all_text_docs:\n",
    "        text_emb_batch = embed_text_chunks(rag, all_text_docs)\n",
    "        tdocs = all_text_docs.copy()\n",
    "        all_text_docs.clear()\n",
    "        _flush_to_faiss_and_mongo(rag, text_emb_batch, tdocs, np.zeros((0, FAISS_DIM), dtype=np.float32), [])\n",
    "\n",
    "    # 4) Iterate image_docs in pages\n",
    "    img_cursor = get_mongo_cursor(img_col, batch_size=batch_size)\n",
    "    for img_doc in img_cursor:\n",
    "        all_img_docs.append(img_doc)\n",
    "\n",
    "        if len(all_img_docs) >= mini_batch_size:\n",
    "            # Embed this mini-batch of images\n",
    "            img_emb_batch = embed_image_docs(rag, all_img_docs)\n",
    "            idocs = all_img_docs.copy()\n",
    "            all_img_docs.clear()\n",
    "\n",
    "            # No text in this flush; pass empty arrays for text\n",
    "            _flush_to_faiss_and_mongo(rag, np.zeros((0, FAISS_DIM), dtype=np.float32), [],\n",
    "                                      img_emb_batch, idocs)\n",
    "\n",
    "    # Final flush for any remaining images\n",
    "    if all_img_docs:\n",
    "        img_emb_batch = embed_image_docs(rag, all_img_docs)\n",
    "        idocs = all_img_docs.copy()\n",
    "        all_img_docs.clear()\n",
    "        _flush_to_faiss_and_mongo(rag, np.zeros((0, FAISS_DIM), dtype=np.float32), [],\n",
    "                                  img_emb_batch, idocs)\n",
    "\n",
    "    # 5) Save the rebuilt FAISS index once at the end\n",
    "    rag.faiss_index.save(FAISS_INDEX_PATH)\n",
    "    print(f\"Reindexed all documents. FAISS index saved to {FAISS_INDEX_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ab9729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Give me a summary of the latest news on AI ethics.\n",
      "Results:\n",
      "Here's a summary of the latest news on AI ethics:\n",
      "\n",
      "There is a growing need for more actionable AI ethics guidelines developed by the AI community itself, not just corporations and governments, to ensure the community's values are reflected and followed. As mentioned in [\"AI ethics must be actionable\"](https://www.deeplearning.ai/the-batch/ai-ethics-must-be-actionable), deeplearning.ai hosted a Pie & AI event on AI and ethics across four cities, and participants suggested actionable ethics statements for AI engineers.\n",
      "\n",
      "However, many companies investing in AI are not adequately addressing the ethical issues and social biases that AI raises. As reported in [\"Irresponsible AI\"](https://www.deeplearning.ai/the-batch/irresponsible-ai), a Fico report revealed that while AI investments are growing, efforts to ensure AI is ethical, responsible, and free of bias are not keeping pace. A substantial percentage of large companies are not ready for AI transformation on an ethical level, which could lead to alienated customers and legal violations.\n",
      "\n",
      "[AI ethics must be actionable] (https://www.deeplearning.ai/the-batch/ai-ethics-must-be-actionable)\n",
      "[Irresponsible AI] (https://www.deeplearning.ai/the-batch/irresponsible-ai)\n",
      "[Image 1] (https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20SIZED-1-1.png)\n",
      "[Image 2] (https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20SIZED-1-1.png)\n",
      "[Image 3] (https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20SIZED-1-1.png)\n",
      "[Image 4] (https://dl-staging-website.ghost.io/content/images/2021/08/Irresponsible-AI-1.gif)\n",
      "[Image 5] (https://dl-staging-website.ghost.io/content/images/2021/08/Irresponsible-AI-1.gif)\n",
      "[Image 6] (https://dl-staging-website.ghost.io/content/images/2021/08/Irresponsible-AI-1.gif)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Query the filled RAG system\n",
    "query = \"Give me a summary of the latest news on AI ethics.\"\n",
    "results = rag.query_and_generate(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Results:\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
